{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Log= pd.read_excel('Log.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "\n",
    "from tkinter import *\n",
    "from PIL import Image\n",
    "from PIL import ImageTk\n",
    "import imutils\n",
    "\n",
    "def SaveLog(imagen):\n",
    "    Log= pd.read_excel('Log.xlsx')\n",
    "    df2 = {'Fecha': str(datetime.datetime.now()), 'Imagen': imagen}\n",
    "    Log = Log.append(df2, ignore_index = True)\n",
    "    Log.to_excel('Log.xlsx',index=False)\n",
    "def get_video_capture():\n",
    "    \"\"\"\n",
    "    Creates a new video streaming object to extract video frame by frame to make prediction on.\n",
    "    :return: opencv2 video capture object, with lowest quality frame available for video.\n",
    "    \"\"\"\n",
    "    \n",
    "    return cv2.VideoCapture(capture_index)\n",
    "\n",
    "def load_model(model_name):\n",
    "    \"\"\"\n",
    "    Loads Yolo5 model from pytorch hub.\n",
    "    :return: Trained Pytorch model.\n",
    "    \"\"\"\n",
    "    if model_name:\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_name, force_reload=True)\n",
    "    else:\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "    return model\n",
    "\n",
    "def score_frame( frame):\n",
    "    \"\"\"\n",
    "    Takes a single frame as input, and scores the frame using yolo5 model.\n",
    "    :param frame: input frame in numpy/list/tuple format.\n",
    "    :return: Labels and Coordinates of objects detected by model in the frame.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    frame = [frame]\n",
    "    results = model(frame)\n",
    "    labels, cord = results.xyxyn[0][:, -1], results.xyxyn[0][:, :-1]\n",
    "    return labels, cord\n",
    "\n",
    "def class_to_label(x):\n",
    "    \"\"\"\n",
    "    For a given label value, return corresponding string label.\n",
    "    :param x: numeric label\n",
    "    :return: corresponding string label\n",
    "    \"\"\"\n",
    "\n",
    "    return classes[int(x)]\n",
    "\n",
    "def plot_boxes(results, frame):\n",
    "    \"\"\"\n",
    "    Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "    :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "    :param frame: Frame which has been scored.\n",
    "    :return: Frame with bounding boxes and labels ploted on it.\n",
    "    \"\"\"\n",
    "    labels, cord = results\n",
    "    n = len(labels)\n",
    "    x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "    for i in range(n):\n",
    "        row = cord[i]\n",
    "        if row[4] >= 0.3:\n",
    "            x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "            bgr = (0, 255, 0)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)\n",
    "            cv2.putText(frame, class_to_label(labels[i]), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def __call__():\n",
    "    \"\"\"\n",
    "    This function is called when class is executed, it runs the loop to read the video frame by frame,\n",
    "    and write the output into a new file.\n",
    "    :return: void\n",
    "    \"\"\"\n",
    "    cap = get_video_capture()\n",
    "    assert cap.isOpened()\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        assert ret\n",
    "        \n",
    "        frame = cv2.resize(frame, (416,416))\n",
    "        \n",
    "        start_time = time()\n",
    "        results = score_frame(frame)\n",
    "        frame = plot_boxes(results, frame)\n",
    "        \n",
    "        end_time = time()\n",
    "        fps = 1/np.round(end_time - start_time, 2)\n",
    "        #print(f\"Frames Per Second : {fps}\")\n",
    "            \n",
    "        cv2.putText(frame, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "        \n",
    "        cv2.imshow('YOLOv5 Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "def iniciar():\n",
    "    global cap\n",
    "    global contChaleco\n",
    "    global contCasco\n",
    "    global cont\n",
    "    contChaleco=0\n",
    "    contCasco=0\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW) # 0 = WebCam\n",
    "    cont=len(Log)\n",
    "    visualizar()\n",
    "def visualizar():\n",
    "    global cap\n",
    "    global contChaleco\n",
    "    global contCasco\n",
    "    global cont\n",
    "    aprobado=False\n",
    "    assert cap.isOpened()\n",
    "    if cap is not None:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == True:\n",
    "            frame = imutils.resize(frame, width=640)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            start_time = time()\n",
    "            results = score_frame(frame)\n",
    "            frame = plot_boxes(results, frame)\n",
    "\n",
    "            end_time = time()\n",
    "            fps = 1/np.round(end_time - start_time, 2)\n",
    "            #print(f\"Frames Per Second : {fps}\")\n",
    "                \n",
    "            cv2.putText(frame, f'FPS: {int(fps)}', (20,70), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "            im = Image.fromarray(frame)\n",
    "            img = ImageTk.PhotoImage(image=im)\n",
    "            lblVideo.configure(image=img)\n",
    "            lblVideo.image = img\n",
    "            if len(results[0])==2:\n",
    "                if (class_to_label(results[0][0])=='chaleco' and class_to_label(results[0][1])=='casco') or (class_to_label(results[0][0])=='casco' and class_to_label(results[0][1])=='chaleco'):\n",
    "                    contChaleco+=1\n",
    "                    contCasco+=1\n",
    "            if contChaleco>4 and contCasco>4:\n",
    "                contChaleco=0\n",
    "                contCasco=0\n",
    "                print('si se pudo')\n",
    "                image = ImageTk.PhotoImage(file = \"Images\\Cheque.png\")\n",
    "                imageLabel.configure(image = image)\n",
    "                imageLabel.image = image\n",
    "                cont+=1\n",
    "                cv2.imwrite('RegistroFotos/'+'empleado'+str(cont)+'.png',frame)\n",
    "                SaveLog('RegistroFotos/'+'empleado'+str(cont)+'.png')\n",
    "                aprobado=True\n",
    "                \n",
    "            else:\n",
    "                image = ImageTk.PhotoImage(file = \"Images\\cerrar.png\")\n",
    "                imageLabel.configure(image = image)\n",
    "                imageLabel.image = image\n",
    "            if aprobado:\n",
    "                aprobado=False\n",
    "            lblVideo.after(1000, visualizar)\n",
    "        else:\n",
    "            lblVideo.image = \"\"\n",
    "            cap.release()\n",
    "def finalizar():\n",
    "    global cap\n",
    "    cap.release()      \n",
    "        \n",
    "# Create a new object and execute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\Jorge/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-11-13 Python-3.10.8 torch-1.13.0+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7015519 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "capture_index=0\n",
    "model_name='best.pt'\n",
    "capture_index = capture_index\n",
    "model = load_model(model_name)\n",
    "classes = model.names\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root = Tk()\n",
    "btnIniciar = Button(root, text=\"Iniciar\", width=45, command=iniciar)\n",
    "btnIniciar.grid(column=0, row=0, padx=5, pady=5)\n",
    "btnFinalizar = Button(root, text=\"Finalizar\", width=45, command=finalizar)\n",
    "btnFinalizar.grid(column=1, row=0, padx=5, pady=5)\n",
    "lblVideo = Label(root)\n",
    "lblVideo.grid(column=0, row=1, columnspan=2)\n",
    "imageLabel =Label(root)\n",
    "imageLabel.grid(column=2, row=1, columnspan=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04c99251120b9783bb57db04925b02d6d9a65330f6ca271b364357389b908c1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
